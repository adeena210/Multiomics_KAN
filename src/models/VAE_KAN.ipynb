{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from preprocessing import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../efficientkan')\n",
    "from efficient_kan import KAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=400, latent_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder layers\n",
    "        self.fc1 = KAN([input_dim, hidden_dim])\n",
    "        self.fc21 = KAN([hidden_dim, latent_dim])  # Mean of the latent space\n",
    "        self.fc22 = KAN([hidden_dim, latent_dim])  # Log variance of the latent space\n",
    "\n",
    "        # Decoder layers\n",
    "        self.fc3 = KAN([latent_dim, hidden_dim])\n",
    "        self.fc4 = KAN([hidden_dim, input_dim])\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)  # Sample from standard normal distribution\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.tanh(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "    def loss_function(recon_x, x, mu, logvar):\n",
    "        recon_loss = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return recon_loss + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: VAE, epochs, trainloader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    optimizer = optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    model.train()\n",
    "    for epoch in epochs:\n",
    "        train_loss = 0\n",
    "        for batch_idx, (data,) in enumerate(trainloader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss = model.loss_function(recon_batch, data, mu, logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        print(f'Epoch {epoch + 1}, Loss: {train_loss / len(trainloader.dataset):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m input_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data/exprMatrix.tsv\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      2\u001B[0m meta_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data/meta.tsv\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 3\u001B[0m trainloader, input_dim \u001B[38;5;241m=\u001B[39m \u001B[43mpreprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmeta_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m vae \u001B[38;5;241m=\u001B[39m VAE(input_dim\u001B[38;5;241m=\u001B[39minput_dim)\n",
      "File \u001B[0;32m~/Documents/Personal_Projects/Multiomics_KAN/src/preprocessing.py:10\u001B[0m, in \u001B[0;36mpreprocess\u001B[0;34m(input_path, meta_path, batch_size)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpreprocess\u001B[39m(input_path, meta_path, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m):\n\u001B[0;32m---> 10\u001B[0m     adata \u001B[38;5;241m=\u001B[39m \u001B[43msc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     meta \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data/meta.tsv\u001B[39m\u001B[38;5;124m\"\u001B[39m, sep\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     12\u001B[0m     adata\u001B[38;5;241m.\u001B[39mvar \u001B[38;5;241m=\u001B[39m meta\n",
      "File \u001B[0;32m~/Documents/Personal_Projects/personal/lib/python3.12/site-packages/anndata/_io/read.py:360\u001B[0m, in \u001B[0;36mread_text\u001B[0;34m(filename, delimiter, first_column_names, dtype)\u001B[0m\n\u001B[1;32m    358\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    359\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m filename\u001B[38;5;241m.\u001B[39mopen() \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m--> 360\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdelimiter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfirst_column_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Personal_Projects/personal/lib/python3.12/site-packages/anndata/_io/read.py:442\u001B[0m, in \u001B[0;36m_read_text\u001B[0;34m(f, delimiter, first_column_names, dtype)\u001B[0m\n\u001B[1;32m    440\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m first_column_names:\n\u001B[1;32m    441\u001B[0m     row_names\u001B[38;5;241m.\u001B[39mappend(line_list[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m--> 442\u001B[0m     data\u001B[38;5;241m.\u001B[39mappend(\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mline_list\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    444\u001B[0m     data\u001B[38;5;241m.\u001B[39mappend(np\u001B[38;5;241m.\u001B[39marray(line_list, dtype\u001B[38;5;241m=\u001B[39mdtype))\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "input_path = \"../data/exprMatrix.tsv\"\n",
    "meta_path = \"../data/meta.tsv\"\n",
    "trainloader, input_dim = preprocess(input_path, meta_path)\n",
    "vae = VAE(input_dim=input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train(vae, 1, trainloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
